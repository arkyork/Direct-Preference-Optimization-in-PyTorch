{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82d1d4e4f114abea2596690d8d7280f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n",
    "model=\"meta-llama/Meta-Llama-3-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"HumanLLMs/Human-Like-DPO-Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=ds[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def tokenize_dataset(batch):\n",
    "    # Tokenize prompt, chosen, and rejected\n",
    "    prompt_token = tokenizer(batch['prompt'], padding=True, return_tensors=\"pt\")\n",
    "    chosen_token = tokenizer(batch['chosen'], padding=True, return_tensors=\"pt\")\n",
    "    rejected_token = tokenizer(batch['rejected'], padding=True, return_tensors=\"pt\")\n",
    "    \n",
    "    # Add eos_token\n",
    "    chosen_token['input_ids'] = torch.cat(\n",
    "        [chosen_token['input_ids'], torch.tensor([[tokenizer.eos_token_id]])], dim=1\n",
    "    )\n",
    "    chosen_token['attention_mask'] = torch.cat(\n",
    "        [chosen_token['attention_mask'], torch.tensor([[1]])], dim=1\n",
    "    )\n",
    "\n",
    "    rejected_token['input_ids'] = torch.cat(\n",
    "        [rejected_token['input_ids'], torch.tensor([[tokenizer.eos_token_id]])], dim=1\n",
    "    )\n",
    "    rejected_token['attention_mask'] = torch.cat(\n",
    "        [rejected_token['attention_mask'], torch.tensor([[1]])], dim=1\n",
    "    )\n",
    "\n",
    "    # Concatenate prompt with chosen and rejected\n",
    "    batch['chosen_tokenizer'] = {\n",
    "        'input_ids': torch.cat([prompt_token['input_ids'], chosen_token['input_ids']], dim=1),\n",
    "        'attention_mask': torch.cat([prompt_token['attention_mask'], chosen_token['attention_mask']], dim=1),\n",
    "    }\n",
    "    batch['rejected_tokenizer'] = {\n",
    "        'input_ids': torch.cat([prompt_token['input_ids'], rejected_token['input_ids']], dim=1),\n",
    "        'attention_mask': torch.cat([prompt_token['attention_mask'], rejected_token['attention_mask']], dim=1),\n",
    "    }\n",
    "    batch[\"chosen\"]=batch[\"prompt\"]+batch[\"chosen\"]\n",
    "    batch[\"rejected\"]=batch[\"prompt\"]+batch[\"rejected\"]\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15410ebfab44be288458bf1d1fac984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_ds=train_dataset.map(tokenize_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0番目のデータを取得\n",
    "tokenized_sample = token_ds[0]\n",
    "\n",
    "# chosen と rejected のデータを取得\n",
    "chosen_ids = torch.tensor(tokenized_sample['chosen_tokenizer']['input_ids']).to(model.device)\n",
    "rejected_ids = torch.tensor(tokenized_sample['rejected_tokenizer']['input_ids']).to(model.device)\n",
    "\n",
    "# モデルに入力してロジットを計算\n",
    "with torch.no_grad():\n",
    "    chosen_outputs = model(input_ids=chosen_ids)\n",
    "    rejected_outputs = model(input_ids=rejected_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 56, 128256])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_log_softmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_logits = chosen_outputs.logits  # (batch_size, seq_len, vocab_size)\n",
    "rejected_logits = rejected_outputs.logits  # 同様\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 56, 128256])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen is preferred.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# log softmax を計算\n",
    "chosen_log_softmax = chosen_logits.log_softmax(dim=-1)\n",
    "rejected_log_softmax = rejected_logits.log_softmax(dim=-1)\n",
    "\n",
    "# chosen と rejected の log probabilities を取得\n",
    "chosen_logps = torch.gather(\n",
    "    chosen_log_softmax, dim=2, index=chosen_ids.unsqueeze(2)\n",
    ").squeeze(2)  # (batch_size, seq_len)\n",
    "\n",
    "rejected_logps = torch.gather(\n",
    "    rejected_log_softmax, dim=2, index=rejected_ids.unsqueeze(2)\n",
    ").squeeze(2)  # 同様\n",
    "\n",
    "# 合計スコアを計算\n",
    "chosen_score = chosen_logps.sum(dim=1) # 各サンプルのスコア\n",
    "rejected_score = rejected_logps.sum(dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if chosen_score > rejected_score:\n",
    "    print(\"Chosen is preferred.\")\n",
    "else:\n",
    "    print(\"Rejected is preferred.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000,  12174,     11,    358,   1120,   5602,    279,   1888,  42285,\n",
       "            482,    617,    499,   3970,    433,     30, 128000,     40,   2846,\n",
       "            459,  21075,  11478,   4221,   1646,     11,    358,   1541,    956,\n",
       "            617,   4443,  11704,    477,  18463,     13,   4452,     11,    358,\n",
       "            649,   3493,    499,    449,   2038,    389,   7701,  55985,    323,\n",
       "          41440,  50082,  12631,     11,    439,   1664,    439,  19075,   3196,\n",
       "            389,   3230,  36744,    477,  22100,     13,  19418,    499,   1093,\n",
       "            757,    311,   4284,   1063,  28289,   9698,    477,   4358,    264,\n",
       "           4040,  17779,    315,   2802,     30, 128001]], device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rejected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen score: -632.5\n",
      "Rejected score: -890.0\n"
     ]
    }
   ],
   "source": [
    "# 結果を比較\n",
    "chosen_score_mean = torch.mean(chosen_score)\n",
    "rejected_score_mean = torch.mean(rejected_score)\n",
    "print(f\"Chosen score: {chosen_score.item()}\")\n",
    "print(f\"Rejected score: {rejected_score.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # log softmax を計算\n",
    "    chosen_log_softmax = chosen_logits.log_softmax(dim=-1)\n",
    "    rejected_log_softmax = rejected_logits.log_softmax(dim=-1)\n",
    "\n",
    "    # chosen と rejected の log probabilities を取得\n",
    "    chosen_logps = torch.gather(\n",
    "        chosen_log_softmax, dim=2, index=chosen_ids.unsqueeze(2)\n",
    "    ).squeeze(2)  # (batch_size, seq_len)\n",
    "\n",
    "    rejected_logps = torch.gather(\n",
    "        rejected_log_softmax, dim=2, index=rejected_ids.unsqueeze(2)\n",
    "    ).squeeze(2)  # 同様\n",
    "\n",
    "    # 合計スコアを計算\n",
    "    chosen_score = chosen_logps.sum(dim=1) # 各サンプルのスコア\n",
    "    rejected_score = rejected_logps.sum(dim=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
